\input{common}
%\addtolength{\textheight}{7em}
\let\oldaddcontentsline\addcontentsline% Store \addcontentsline

\sloppy
\setcounter{tocdepth}{5}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\usepackage{showframe}
\usepackage{lipsum}
\usepackage{xcolor}

\usepackage{enumitem}
\newlist{myQuoteEnumerate}{enumerate}{2}% Set max nesting depth
\setlist[myQuoteEnumerate,1]{label=(\arabic*)}% Use numbers for level 1
\setlist[myQuoteEnumerate,2]{label=(\alph*)}%   Use letters for level 2

\newenvironment{MyQuote}{%
    \begin{myQuoteEnumerate}[resume=*,series=MyQuoteSeries]%
    \color{blue}%
    \item \begin{quote}%
}{%
    \end{quote}%
    \end{myQuoteEnumerate}%
}%
%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{lineno}
%\iffalse
\usepackage{xcolor}
\usepackage{lineno}
\usepackage{lipsum}
\makeatletter
\renewcommand{\linenumberfont}{\fontsize{12pt}{3pt}\normalfont\smaller\color{gray}}
\makeatother
%\usepackage{lineno}
%\linenumbers
%\fi
%%%%%%%%%%%%%%%%%%%%%%%%
\linespread{1.0}
%%%%%%%%%%%%%%%%%%%%%%%%
\makeatletter
\renewcommand\tableofcontents{%
    \@starttoc{toc}%
}
\makeatother


\begin{document}
\vspace*{-9em}
\title{\tcode{Generalisation of nth_element to a range of nths}}
\author{
Johan Lundberg\\
}
\date{} %unused. Type date explicitly below.
\maketitle
\vspace*{-5em}

\begin{tabular}{ll}
Document \#:& D2375R1\\
Date: &2021-12-26 \\
Project: & Programming Language C++ \\
Audience: & LEWG \\
Email: &\href{mailto:lundberj@gmail.com}{lundberj@gmail.com}
\end{tabular}

\iffalse %%% FOR ONLINE ABSTRACT
The paper proposes a generalisation of \tcode{std::nth_element}, taking a sorted range of iterators instead of a single nth element iterator, allowing arbitrary partial sorting of any sortable range.
The use and analysis of such algorithms is widespread and mature[Alsuwaiyel2001,Panh2002,lent1996,Shen1997]  and is available to Python programmers as numpy.partition[NpPart,NPImpl] since 2014.
\fi

\subsection*{Contents}
\renewcommand{\baselinestretch}{1.0}\normalsize
\tableofcontents
\renewcommand{\baselinestretch}{1.2}\normalsize

\subsection*{Revision history vs R0}

2021-12-16: Added clarifications and more background, explanations, wording clarifications, references, summarized performance study, applications, more questions/answers. --Based on feedback and material sent to SG9 list 2021-12-09. Synopsis: \tcode{S last} argument was missing 2021-12-19.
2021-12-25: Simplified wording (change marked at section \ref{synopsis}). Added images for equalization example. Formatting and typos. Added example of \emph{Before} with projections, and example \emph{Before} with fixed size m=5.\newline 
2021-12-26: Added explanatory images to the introduction.

\section{Introduction}
The paper proposes a generalisation of \tcode{std::nth_element}, taking a sorted range of iterators instead of a single \tcode{nth} iterator, allowing arbitrary partial sorting of any sortable range.

The use and analysis of such algorithms is widespread and mature\cite{Alsuwaiyel2001,Panh2002,lent1996,Shen1997} and is available to Python programmers as \tcode{numpy.partition}\cite{NpPart,NPImpl} since 2014.

The single-nth \tcode{nth_element} algorithm has been part of the C++ standard library since the beginning\cite{StepLee95}, introduced as \dblquotes{\ldots  the  element  in  the  position  pointed  to  by nth  is  the  element  that  would  be  in  that position if the whole range were sorted. Also for any iterator i in the range [first, nth) and any iterator j in the range [nth, last) it holds that !(*i > *j) or comp(*i, *j) == false. It is linear on the average.}

\emph{This} proposal extends the usability of \tcode{std::nth_element} to multiple \tcode{nths}. 
That is, the previously stated post condition holds for all nth in \tcode{nths}. In other words, at each nth the range is arranged as if sorted, and all elements after each nth are no less than the element at that location.

Just as with the current standard single-nth version of \tcode{std::nth_element} the purpose is \emph{faster operation}, but just as with the single-nth version, there is additional \emph{semantic clarity} in performing only the required partitioning. 
In this specific sense it's in the same category as \tcode{std::partial_sort}.

A possible implementation of the range-of-nths algorithm is provided (section \ref{Implementation}).
It translates naturally to \tcode{std::ranges} versions just like \tcode{std::nth_element}, returning \tcode{last}.

Current alternatives are either at least somewhat hard to write correctly and/or less performant.

To clarify what is new, the addition is here called \tcode{std::nth_element\underline{s}}, but is proposed to go as \tcode{nth_element}. 

\newpage
\subsection{Visual explanation}
\subsubsection*{Single-nth \tcode{nth_element}}

As example data, consider the permuted integers [100,126) at index [0,26) and the sorted counterpart:\\[0.41em]
\includegraphics[width=0.999\textwidth]{plotting/figs/rnd.png}\\[0.41em]
\includegraphics[width=0.999\textwidth]{plotting/figs/sort.png}\\[0.41em]
What the current-standard \tcode{std::nth_element} does is to arrange and partition the data as described in the previous section. For example, with \tcode{nth = begin+7}, the element in the position pointed to by nth is the element that  would  be  in  that position if the whole range were sorted, and all subsequent values are no less than that value:

\includegraphics[width=0.999\textwidth]{plotting/figs/1a.pdf},

or for \tcode{nth = begin+20}:

\includegraphics[width=0.999\textwidth]{plotting/figs/1b.pdf}.

\subsubsection*{Range-of-nth \tcode{nth_element}}

This proposal adds the possibility to provide a range of nths, such as \tcode{\{begin+7,begin+20\}} :

\includegraphics[width=0.999\textwidth]{plotting/figs/2.pdf}

or at \tcode{\{7,12,20\}}:

\includegraphics[width=0.999\textwidth]{plotting/figs/3.pdf}

or  at \tcode{\{5,6,14,15\}}:

\includegraphics[width=0.999\textwidth]{plotting/figs/qs.pdf}

\newpage
\section{The algorithm}
\label{Implementation}
\label{Implement}

The proposal can be implemented with an algorithm that partitions the data on the midpoint of nths using the single-nth \tcode{nth_element} and proceeds to recurse into the two partitions. Ref \cite{Alsuwaiyel2001} considers this algorithm and concludes
 complexity \mbox{O(N log m)} where \mbox{N = last - first} and m is the number of unique elements in nths.
The same paper presents a parallel version, building on refs \cite{Akl1984,Akl1989,Shen1997}.

In many applications m is constant and the complexity as function of N alone is naturally linear on average. On the other hand, in the worst case m varies with N as \mbox{m = N}, and the whole container is sorted. For parallel versions (overloads taking an ExecutionPolicy) it is reasonable to leave freedom to implementers to do a full parallel sort and allow \mbox{O(N log N)}.

Python has numpy.partition\cite{NpPart} as their incarnation of \tcode{ntn_element}.
It supports a range-of-nths as proposed here and the implementation\cite{NPImpl} (in C++) uses \mbox{Introselect\cite{Musser1997}} by specification\footnote{numpy.partition and the in-place version numpy.ndarray.partion do not state complexity in terms of M (the size of nths) or m (the number of unique nths), but appears to be \mbox{$\sim$ N log M} for reasonable M, to become \mbox{$\sim$ N $\cdot$ M} for large M, such as M>1e4, N=1e6. }.

A possible implementation\footnote{
The implementation is not the point of the proposal but it may help explain it. Feedback would be very much appreciated. 
The algorithm described in \cite{Alsuwaiyel2001} is a little bit simpler since it takes \emph{unique} nths, something that is not reasonable to require here. The algorithms is \mbox{O(N log m)} except for a small N-independent term \mbox{O(M-m)} where M is the size of nths, due to the iterator comparisons and increments in \tcode{find_if_not} to skip over doublets in nths. The first if-statement is found in existing single-nth \tcode{nth_element} implementations, but here it also prevents some unnecessary bisections of nths.}\cite{p2375RefImpl}
is shown below. Comparisons and projections can also be fed through in the most natural way. 

\begin{codeblock}
template< class RandomAccessIterator, class RandomAccessIterator2 >
constexpr void @\textbfx{nth_elements}@(RandomAccessIterator first, 
  RandomAccessIterator2 nth_first, RandomAccessIterator2 nth_last, 
  RandomAccessIterator last)
{
  if (last - first <= 32) { @\textbfx{std::sort(first, last)}@; return; }
  const auto nth_dist = nth_last - nth_first;
  if (nth_dist == 0 || *nth_first == last) return;
  const auto nth_mid = nth_first + nth_dist / 2;
  const auto at_nth_mid = *nth_mid;
  @\textbfx{nth_element(first, at_nth_mid, last)}@;
  @\textbfx{nth_elements(first, nth_first, nth_mid, at_nth_mid)}@;
  if (at_nth_mid != last){
    const auto nth_left = std::find_if_not(nth_mid, nth_last, 
      [at_nth_mid](auto v) {return v == at_nth_mid; });
    @\textbfx{nth_elements(at_nth_mid + 1, nth_left, nth_last, last)}@;
  }
}

\end{codeblock}

\section{Tony Tables (Before/After)}

Existing alternatives are to sort the whole container or to figure out a series of calls to e.g. \tcode{nth_element} and \tcode{partial_sort}. 
The examples below could be the linear time partitioning of messages to be
processed into fixed sized priority buckets, keeping or dropping remaining messages. Or finding the fastest 25, 100, and 1000 race participants in linear time. 
The partitions themselves form half open ranges so it's easy to e.g. sort and
print the 100th up to the 1000th fastest runners by name. 

Context: partitioning into a fixed number of slots
\begin{codeblock}
vector<decltype(v)::iterator> nths;
for(size_t slot=1; slot<16 ; ++slot){
	nths.push_back(v.begin()+ min(slot*2048,N));
}
\end{codeblock}
or at some other arbitrary iterators in the inclusive range [first,last].
\begin{codeblock}
auto nths=vector{v.begin()+25,v.begin()+100,v.begin()+1000}; 
\end{codeblock}

\subsection*{After \textnormal{ Simple and O(N)}}

For all examples, the Tony Tables--\emph{After} case is the same:\newline

\hspace{3ex}\begin{tabular}{|l|} 
  \hline 
  \textbf{$\star \star$ After $\star \star$} \\
  \hline 
\begin{codeblock} 
nth_elements(v, nths, pred);
\end{codeblock}\\[1em]
or, for the examples using a projection:
\\
\begin{codeblock} 
nth_elements(v, nths, pred, proj);
\end{codeblock} 
\\
\hline 
\end{tabular} 


\subsection*{Alternative 1a: Hand-wired bisection for nths of known size 3. O(N) but messy}

\hspace{3ex}\begin{tabular}{|l|} 
  \hline 
  \textbf{Before} \\
  \hline 
\begin{codeblock} 
nth_element(v.begin(), nths[1], v.end(), pred);
nth_element(v.begin(), nths[0], nths[1], pred);
nth_element(nths[1]+1, nths[2], v.end(), pred);
\end{codeblock} 
\\
\hline 
\end{tabular} 

Did we get this right? Is it correct for repeated nths or empty v?
This is an attempt at manually figuring out and hand-inlining \emph{this} proposal for a know nths size equal to 3.

If we are using a projection, we must use sub-ranges or something to the same effect (and with the same risk of corner-case bugs, eg missed +1 at the right places):

\hspace{3ex}\begin{tabular}{|l|} 
  \hline 
  \textbf{Before} \\
  \hline 
\begin{codeblock} 
ranges::nth_element(v, nths[1], pred, proj);
ranges::nth_element(sub_range(v.begin(),nths[1]), nths[0], pred, proj);
ranges::nth_element(sub_range(nths[1]+1,v.end()), nths[2], pred, proj);
\end{codeblock} 
\\
\hline 
\end{tabular} 
\subsection*{Alternative 1b: Hand-wired bisection for nths of known size 5. O(N) but messy}

\hspace{3ex}\begin{tabular}{|l|} 
  \hline 
  \textbf{Before} \\
  \hline 
\begin{codeblock} 
nth_element(v.begin(), nths[5/2-1], v.end(), pred);
nth_element(v.begin(), nths[(5/2)/2-1], nths[5/2-1], pred);
nth_element(nths[(5/2)/2-1]+1, nths[5/2-1], v.end(), pred);
nth_element(nths[(5/2)-1]+1, nths[(5/2)/2+5/2-1], nths[5-1]), pred);
nth_element(nths[5-1]+1, nths[(5/2)/2+5/2-1], v.end(), pred);
\end{codeblock} 
\\
\hline 
\end{tabular} 

Did we get this right?

\subsection*{Alternative 1c: Hand-wired for size 3. O(N $\cdot$ M)}

Hand-wired simpler alternative. Easier to figure out, but O(N $\cdot$ M):

\hspace{3ex}\begin{tabular}{|l|} 
  \hline 
  \textbf{Before} \\
  \hline 
\begin{codeblock} 
nth_element(v.begin(), nths[0],v.end(), pred);
nth_element(nths[0]+1, nths[1], v.end(), pred);
nth_element(nths[1]+1, nths[2], v.end(), pred);
\end{codeblock} 
\\
\hline 
\end{tabular} 

Did we get this right?

\subsection*{Alternative 2: Simple but O(N log N)}

\hspace{3ex}\begin{tabular}{|l|} 
  \hline 
  \textbf{Before} \\
  \hline 
\begin{codeblock} 
sort(v,pred);
\end{codeblock}
\\
\hline 
\end{tabular} 

\section{Examples and Applications}

It partitions into any number of partitions as shown in the previous section. Further examples and applications follow.

\subsection{\tcode{nth_elements} and sort}

Partitioning a bunch of ponies into several age groups, then sort one group by name.

\begin{codeblock}
struct Pony{
  double littleness; 
  chrono::duration age;
  string name;
};
auto end=nth_elements(v, nths, std::greater{}, Pony::age);
std::sort(nths[3], nths[4], std::less{}, Pony::name);
\end{codeblock}

\subsection{\tcode{nth_elements} into slots}
Context: partitioning into a fixed number of slots
\begin{codeblock}
vector<decltype(v)::iterator> nths;
for(size_t slot=1; slot<16 ; ++slot){
	nths.push_back(v.begin()+ min(slot*2048,N));
}
\end{codeblock}
or at some other arbitrary iterators in the inclusive range [first,last].
\begin{codeblock}
auto nths=vector{v.begin()+25,v.begin()+100,v.begin()+1000}; 
\end{codeblock}

\subsection{Outlier filtering}

With two partitioning points, the lowest a, and highest b elements are excluded from a range in constant time with a single call to the proposed extension.

\subsection{Pagination and sorted subset}

A small sorted windows into a large data set can be selected as if sorted by partitioning at two points. For example, if \tcode{j} items fit on a display page, we can jump to page \tcode{k}, that is, into the range from \tcode{a=v.begin()+j*k} to \tcode{b=v.begin()+j*(k+1)}:

\begin{codeblock}
std::nth_element({a,b}, v);
processPage(a,b); // May also now sort the small subrange with std::sort(a,b);
\end{codeblock}

An option is to pre-partition into all pages, exactly as the \emph{slots} example above.

\subsection{Partitioning with interpolation. Quantiles, Percentiles.}

% As such \tcode{nth_element(s)} are general algorithms on any sortable, and are to quantiles what
% \tcode{std::accumulate} and \tcode{std::inner_product} are to statistical mean and weighted mean.

\tcode{nth_elements} can be used to efficiently \emph{implement} the calculation of a single or a range of quantiles.

The current standard single-nth \tcode{std::nth_element} is actually not generally enough to calculate even a single quantile point, such as the median in the way that is often preferred: For example the [median](\url{https://en.wikipedia.org/wiki/Median}) of an even number of elements is typically taken  to be the mean of the two central elements. With the range-of-nth \tcode{nth_element} version single or multiple quantiles can be calculated efficiently.

It's also a common situation to calculate more than one quantile, such as min, 25\%, 50\% (median), 75\%, max. This requires 5 to 8 partition points depending on the size of the data. With \emph{this} proposal this can be done in O(N).

Also note wikipedia on [Percentiles](\url{https://en.wikipedia.org/wiki/Percentile}), and [Estimating quantiles from a
sample](\tcode{https://en.wikipedia.org/wiki/Quantile\#Estimating_quantiles_from_a_sample}).


To do interpolation around each requested quantile (such as the median of even N or a percentile that does not divide N) one may directly partition at two iterators at each requested quantile point. For example, partitioning N elements at a single quantile specified as a divisor d (where d=2 would be median and d=100 would mark the first percentile).


\begin{codeblock}
auto n = N == 0?0:N-1;
auto [q,r] = div(n, d);
auto nths=vector{first+q, first+q+(r>0)}; 
\end{codeblock}

\begin{codeblock}
auto last = nth_elements(v, nths, std::less{}, Pony::littleness);
if (nths[0]!=last){
  cout << nths[0]->name << " " << nths[1]->name ; 
  auto intrp_littleness = lerp(nths[0]->littleness, nths[1]->littleness, r*1.0/d);
}
\end{codeblock}

In the above we did floating point based interpolation, but 
one may stay in integer arithmetic\footnote{\tcode{i_lerp(auto a,auto b,auto r,auto d)\{return a+(r*(b-a))/d;\}}. Yes, there are other ways to express this depending on type, e.g. extra work to avoid overflow.}
 for example when working with chrono durations, iterators and indices. Any type the user knows how to interpolate.

 
\begin{codeblock}
auto last = nth_elements(v, nths, std::less{}, Pony::age);
if (nths[0]!=last){
  auto intrp_dur = i_lerp(nths[0]->age, nths[1]->age, r, d);
}
\end{codeblock}
\label{quantileanything}

In Python, \tcode{numpy.quantile}%
\footnote{
It defaults to the above division by N-1 to do linear interpolation but there's a plethora of variations (nine different modes supported by many statistical libraries and tools) on which indices to use, rounding and interpolation/\mbox{selection} and handling of edge cases. 
A good overview is found in P2119R0 commenting on the paper P1708R4 \dblquotes{Simple Statistical Functions} which proposes user-facing median and quantile similar to \tcode{numpy.partition}, returning by value (not via iterators).}
 takes a range of floating point quantile points in [0.0,1.0] and uses the previously mentioned multi-nth version of \tcode{numpy.partition}%.

\newpage

\subsection{Histogram equalization and bin selection. Application to image equalization} 

Image equalization, or data equalization in general is a data processing technique used to enhanced contrast.\footnote{
The subject is described for example at \url{https://en.wikipedia.org/wiki/Histogram_equalization} and \url{https://www.tutorialspoint.com/dip/histogram_equalization.htm}} 
Equalization makes use of the Cumulative distribution function, CDF\footnote{CDF: \url{https://en.wikipedia.org/wiki/Cumulative_distribution_function}} of the image (or data in general). The cumulative distribution can be estimated by taking the cumulant of a \emph{histogram} of the data. Finding good bins is itself done by histogram equalization, which itself relies on an estimated CDF.

An interesting alternative to cumulant-of-histogram, is to obtain the CDF from ordering the data directly. If this is done with a full sort, and exact descriptive CDF is obtained, resulting in a loss-less equalization (modulo floating point and image format aspects).%
\footnote{A more detailed description of sort-based image equalization: Image enhancement using sorted histogram specification and POCS postprocessing -
Il-Lyong Jung and Chang-Su Kim, 2007 IEEE International Conference on Image Processing, ICIP 2007 Proceedings.}

As a performance optimization we can avoid a full sort, and instead use \tcode{nth_elements} and ensure exact results at specific cumulant values (partition points) in the CDF, such as at 0.25, 0.5, 0.75. That is, we use a range-of-nth partitioning to approximate the full sorted data. Worked through examples are found at \cite{p2375RefImpl}. In summary, consider the following image of Tännforsen (Sweden's greatest waterfall), with three different equalization methods.

\begin{tabular}{|l|l|} 
\hline
Original: & Equalized using full sort\\
\includegraphics[width=0.50\textwidth]{plotting/examples/forsen_roundtrip.small.jpg} &
\includegraphics[width=0.50\textwidth]{plotting/examples/forsen_sort.small.jpg} \\
\hline
Equalized using range-of-nths: m=2: & Equalized using range-of-nths: m=5\\
\includegraphics[width=0.50\textwidth]{plotting/examples/forsen_partition2.small.jpg} &
\includegraphics[width=0.50\textwidth]{plotting/examples/forsen_partition5.small.jpg}\\
\hline
\end{tabular}
\enlargethispage*{1em}

\begin{center}
\includegraphics[width=0.55\textwidth]{plotting/examples/forsen_cdf_approximation.png}
\end{center}
Above, the exact CDF (using sort) of the original image is shown in gray, along with approximations using \emph{range-of-nths}. At m=2, the equalization algorithm is equivalent to mapping the image min,max to grayscale values zero and 1.


\newpage
\section{Wording and Synopsis }

\subsection{First wording draft \protect{\tcode{[alg.nth.element]}}}

\added{Underlined green text} marks additions.

\label{wording}\label{synopsis}

\textbf{1} Let comp be less{} and proj be identity{} for the overloads with no parameters by those names.

\textbf{2} Preconditions: [first, nth) and [nth, last) are valid ranges. For the overloads in namespace std, RandomAccessIterator meets the Cpp17ValueSwappable requirements ([swappable.requirements]), and the type of *first meets the Cpp17MoveConstructible (Table 30) and Cpp17MoveAssignable (Table 32) requirements.
\added{For the overloads taking a range [nths_first,nths_last), \newline RandomAccessIterator2 is a RandomAccess iterator, and *nths_first is convertible to \newline RandomAccessIterator.}

\textbf{3} Preconditions: The elements e of [first, last) are partitioned with respect to the expression bool(invoke(comp, invoke(proj, e), value)).

\textbf{4} Effects: After nth_­element the element in the position pointed to by nth is the element that would be in that position if the whole range were sorted with respect to comp and proj, unless nth==last. Also for every iterator i in the range [first, nth) and every iterator j in the range [nth, last) it holds that: bool(invoke(comp, invoke(proj, *j), invoke(proj, *i))) is false. 
\added{For the overloads taking a range of nths, this holds for all nth in nths}$^\ddagger$

\textbf{5} 
Complexity: For the overloads with no ExecutionPolicy, linear on average.
For the overloads with an ExecutionPolicy, O(N) applications of the predicate, and O(N log N) swaps, where N = last - first. 
\added{For overloads taking a range [nths_first,nths_last) but no ExecutionPolicy the complexity is approximately \mbox{O(N log m + M)} where m is the number of unique elements in [nths_first,nths_last), and M = nths_last - nths_first.
For overloads taking a range [nths_first,nths_last) and an ExecutionPolicy the complexity is \mbox{O(N log N + M)}.}

$\ddagger$: \textbf{Note:} Rev R0 had an different wording with the same intention, but was redundant, as well as incomplete with respect to \emph{comp} and \emph{proj}.

\subsection{Synopsis -- \tcode{<algorithm> [algorithm.syn]}}

Added signatures \tcode{std::}

\begin{codeblockAdd}
template<class RandomAccessIterator, class RandomAccessIterator2>
constexpr void nth_element(
RandomAccessIterator first, 
RandomAccessIterator2 nths_first, RandomAccessIterator2 nths_last,
RandomAccessIterator last);

template<class RandomAccessIterator, class RandomAccessIterator2, class Compare>
constexpr void nth_element(
RandomAccessIterator first, 
RandomAccessIterator2 nths_first, RandomAccessIterator2 nths_last,
RandomAccessIterator last, Compare comp);

template<class ExecutionPolicy, class RandomAccessIterator, class RandomAccessIterator2>
void nth_element(ExecutionPolicy&& exec,
RandomAccessIterator first, 
RandomAccessIterator2 nths_first, RandomAccessIterator2 nths_last,
RandomAccessIterator last);

template<class ExecutionPolicy, class RandomAccessIterator,
class RandomAccessIterator2, class Compare>
void nth_element(ExecutionPolicy&& exec,
RandomAccessIterator first, 
RandomAccessIterator2 nths_first, RandomAccessIterator2 nths_last,
RandomAccessIterator last, Compare comp);

\end{codeblockAdd}

Added signatures \tcode{std::ranges::}

\begin{codeblockAdd}
namespace ranges {
  template<random_access_iterator I, sentinel_for<I> S, 
  random_access_range R2, class Comp = ranges::less, class Proj = identity>
  requires sortable<I, Comp, Proj>
  constexpr I nth_element(I first, R2&& nths, S last, Comp comp = {}, Proj proj = {});

  template<random_access_range R, 
  random_access_range R2,
  class Comp = ranges::less, class Proj = identity>
  requires sortable<iterator_t<R>, Comp, Proj>
  constexpr safe_iterator_t<R>
  nth_element(R&& r, R2&& nths, Comp comp = {}, Proj proj = {});
}
\end{codeblockAdd}

\newpage
\section{Questions and Answers}

Q: What's the best name? A: I suggest to reuse \tcode{nth_element} for discoverability but could as well be a separate name. Numpy calls both single nth and range-of-nths \dblquotes{\tcode{partition}}.

Q: What if \tcode{nths} or [first,last) is empty? A: \tcode{nth_elements} does nothing.

Q: What if some elements of \tcode{nths} are equal to last. A: As with \tcode{nth_element}, not a problem.

Q: What if some elements of \tcode{nths} are equal to each other A: By specification, not a problem.

New questions since P0 below. Many thanks to all who commented.

\subsection{Q: Is there's a need to require \tcode{nths} be \tcode{sized_range}?}

A: Not sure, I don't think so. The example implementation does not use .size().


\subsection{Q: How should the \tcode{nths} be provided?}

The current-standard single-nth version uses a single iterator \tcode{nth} to designate the location in the range. A range of iterators seems to me the most natural way to designate multiple arbitrary locations in a range.

This seem \emph{least-surprise} and offers flexibility as well as natural combination with other operations (such as seen in the examples here and in the proposal). Python uses indices rather than iterators to express locations in lists and arrays, and its incarnation of the proposed algorithm uses range-of-indices (or a single value) to specify the partition point(s)\cite{NpPart}.

\subsection{Q: Benefits and performance beyond Ordo.}

A: The comment is appreciated. Expanded the paper introduction and Examples and Application section. Added performance study, section \ref{perfstudy}.

An interesting discussion of \tcode{std::sort} vs single-nth \tcode{std::nth_element} and \tcode{std::partial_sort} is found at [CppCon 2018: Fred Tingaud "A Little Order: Delving into the STL sorting algorithms"](\url{https://www.youtube.com/watch?v=-0tO3Eni2uo})

\newpage
\section{Reference implementation and practical performance}
\label{perfstudy}

A reference implementation is found at \cite{p2375src}. A performance study is found at \cite{p2375RefImpl} and summarized here. 
\subsubsection*{Time vs \tcode{std::sort} for equidistant partitioning points}

\begin{center}
\includegraphics[width=0.55\textwidth]{plotting/images/partition_points_equidistant_speed_for_n_vs_sort.png}
\end{center}

The above image shows the execution speed of \tcode{nth_element} compared to \tcode{std::sort} for various vector sizes $N$.
The data to sort here consists of randomly shuffled doubles, and the range-of-nths version of \tcode{nth_element} was given different numbers $m$ of evenly spaced partitioning points in the vector. Dotted lines show lines $k_i \cdot log(N)$ fitted to pass though each curve at $N=3e6$.

The image shows that the speed curves approximately follow the expected $log(N)$ shape, with different factors for different $m$.

The following table shows a few speedup factors (rough read from the plot) for a number of unique partitioning points $m$ and vector sizes $N$.

\begin{center}
\begin{tabular}{|r|c|c|} % <-- Alignments: 1st column left, 2nd middle and 3rd right, with vertical lines in between
  \hline 
  \textbf{m} & \textbf{speedup factor} & \textbf{at N}\\
  \hline 
1 & 10 & $N=3e7$\\
5 & 5 & $N=3e7$\\
500 & 2 & $N=3e7$\\
\hline
10 & 3 & $N=3e5$\\
50 & 2 & $N=3e5$\\
\hline
5 & 2 & $N=3e3$\\
  \hline 
\end{tabular}
\end{center}

Some care is required when interpreting the plot at low N: For example at the curve $m=1000$. $N=300$, the actual number of partitioning points are saturated to $N$, that is $300$ unique partitioning points. Still, one can say, that as $N$ decreases and approaches $m$ the performance is worse than \tcode{std::sort}, but the speed in these tests are still about $80\%$ of \tcode{std::sort} even for $m \sim N$. The benefit of \tcode{nth_element} over \tcode{sort} grows with $N$ as $log N$. Further slices and ways to plot the same performance data is found at \cite{p2375RefImpl}. It also shows the study repeated for uniformly random (unique) partition points with very similar conclusion, but slightly better performance.


\section*{Acknowledgements}
\addcontentsline{toc}{section}{Acknowledgements}

Many thanks to undisclosed proofreaders and to 
Albin Fredriksson and Marco Rubini for helpful discussions. Many thanks to all who gave comments and feedback.

\renewcommand{\bibname}{References}
\bibliographystyle{abstract}
\bibliography{ref}

\renewcommand{\addcontentsline}[3]{}% Make \addcontentsline a no-op
\begin{thebibliography}{9}
\oldaddcontentsline{toc}{section}{References}

\bibitem[StepLee95]{StepLee95}
Alexander Stepanov and Meng Lee: The Standard Template Library.\\HP Laboratories Technical Report 95-11(R.1), November 14, 1995 \\
\url{http://stepanovpapers.com/STL/DOC.PDF }

\bibitem[Alsuwaiyel2001]{Alsuwaiyel2001} 
Muhammad H. Alsuwaiyel: An optimal parallel algorithm for the multiselection problem. 
Parallel Computing Volume 27, Issue 6, May 2001, Pages 861-865\\
\url{https://doi.org/10.1016/S0167-8191(00)00095-8 }
\bibitem[Akl1984]{Akl1984} 
S. G. Akl, Optimal parallel algorithms for computing convex hulls and for sorting, Computing, 33 (1984), 1-11.
\bibitem[Akl1989]{Akl1989} 
S. G. Akl, The Design and Analysis of Parallel Algorithms (PrenticeHall, Englewood Cliffs, New Jersey, 1989).
%M. L. Fredman and T. H. Spencer, Refined complexity analysis for heap operations, Journal of Computer and
%System Sciences, (1987), 269-284.
\bibitem[Shen1997]{Shen1997} 
H. Shen, Optimal parallel multiselection on EREW PRAM, Parallel Computing, 23(1997), 1987-1992.

\bibitem[NpPart]{NpPart}
Python numpy.partition \\
\url{https://numpy.org/doc/stable/reference/generated/numpy.partition.html }

\bibitem[NPImpl]{NPImpl}
The implementation of partition (multiple and single nth version) is found at
{\footnotesize \url{https://github.com/numpy/numpy/blob/v1.20.2/numpy/core/src/multiarray/item_selection.c#L1023 }}

\bibitem[Musser1997]{Musser1997}
David R. Musser, Introspective Sorting and Selection Algorithms\\
Software--Practice and Experience, (8): 983-993 (1997))\\
\url{https://www.cs.rpi.edu/~musser/gp/algorithms.html }

\bibitem[Panh2002]{Panh2002}
Alois Panholzer --
Analysis of multiple quickselect variants\\
Theoretical Computer Science
Volume 302, Issues 1–3, 13 June 2003, Pages 45-91\\
\url{https://doi.org/10.1016/S0304-3975(02)00729-6 }

\bibitem[lent1996]{lent1996}
Janice Lent, Hosam M.Mahmoud\\
Average-case analysis of multiple Quickselect: An algorithm for finding order statistics\\
Statistics \& Probability Letters \\
Volume 28, Issue 4, August 1996, Pages 299-310
\url{https://doi.org/10.1016/0167-7152(95)00139-5}


\bibitem[p2375RefImpl]{p2375RefImpl}
Performance study and usage examples on \emph{this} proposal.\\
\url{https://github.com/jmlundberg/nth_element_material}

\bibitem[p2375src]{p2375src}
Document source for \emph{this} proposal including reference implementation\\
\url{https://github.com/jmlundberg/p2375}

\end{thebibliography}
\let\addcontentsline\oldaddcontentsline% Restore \addcontentsline

\end{document}
